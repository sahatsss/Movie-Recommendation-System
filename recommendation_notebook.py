# -*- coding: utf-8 -*-
"""recommendation_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c8Ni-hmCId6IKRl9U_BknPjHf11owkxP

# **1. Import Library**
"""

import os
import numpy as np
import pandas as pd

import seaborn as sns
import plotly.express as px
import matplotlib.pyplot as plt

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Embedding, Flatten, Dot, Dense, Input

import warnings

"""# **2. Load Dataset**

mengambil 2 dataset berbeda credit dan movie
"""

df_credit = pd.read_csv(r'\Users\asus\Downloads\archive (11)\tmdb_5000_credits.csv')
df_movies = pd.read_csv(r'\Users\asus\Downloads\archive (11)\tmdb_5000_movies.csv')

df_ratings = pd.read_csv(r'\Users\asus\Downloads\ratings_small\ratings_small.csv')

"""# **3. Eksplorasi Data**

dataframe credit dengan 4 kolom
"""

df_ratings

print('Banyak user: ', len(df_ratings.userId.unique()))
print('user: ', df_ratings.userId.unique())

print('Banyak film yang direview: ', len(df_ratings.movieId.unique()))
print('user: ', df_ratings.movieId.unique())

df_credit

print('Banyak judul: ', len(df_credit.title.unique()))
print('Judul: ', df_credit.title.unique())

"""dataframe movies dengan  20 kolom"""

df_movies

print('Banyak judul: ', len(df_movies.title.unique()))
print('Judul: ', df_movies.title.unique())

top_titles = df_movies.sort_values(by='popularity', ascending=False).head(10)
plt.figure(figsize=(10, 6))
sns.barplot(data=top_titles, x='popularity', y='title', palette='Blues_d')
plt.title("Top 10 Movie Titles by Popularity")
plt.xlabel("Popularity")
plt.ylabel("Title")
plt.tight_layout()
plt.show()

"""# **4. Data Preprocessing**

Menggabungkan dataframe movies dan credit
"""

df_credit = df_credit.rename(columns={'movie_id': 'id'})
df_merged = df_movies.merge(df_credit[['id', 'cast', 'crew']], on='id', how='left')

"""Contoh 5 baris teratas"""

df_merged.head(5)

df_ratings = df_ratings[df_ratings['movieId'].isin(df_merged['id'])]

"""# **5. Data Preparation**"""

df_merged

df_merged.isna().sum()

df_merged.drop(['homepage'], axis = 1, inplace=True)
df_merged.dropna(inplace = True)

df_merged.duplicated().sum()

df_merged.isna().sum()

df_merged.info()

df_ratings['id'] = df_ratings['movieId']
df_ratings.drop(['movieId'], axis=1, inplace=True)
df_ratings

df_ratings.isna().sum()

df_ratings.info()

"""# **6. Model Development dengan Content Based Filtering**"""

df_movies['overview'] = df_movies['overview'].fillna('')
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df_movies['overview'])

cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
indices = pd.Series(df_movies.index, index=df_movies['title']).drop_duplicates()

def recommend(title, cosine_sim=cosine_sim):
    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]
    movie_indices = [i[0] for i in sim_scores]
    return df_movies[['title', 'overview']].iloc[movie_indices]

recommend("Avengers: Age of Ultron")

"""# **7. Proses Training**"""

user_encoder = LabelEncoder()
movie_encoder = LabelEncoder()

df_ratings['user'] = user_encoder.fit_transform(df_ratings['userId'])
df_ratings['movie'] = movie_encoder.fit_transform(df_ratings['id'])

num_users = df_ratings['user'].nunique()
num_movies = df_ratings['movie'].nunique()

class RecommenderNet(Model):
    def __init__(self, num_users, num_movies, embedding_size=50):
        super(RecommenderNet, self).__init__()
        self.user_embedding = Embedding(num_users, embedding_size, embeddings_initializer='he_normal')
        self.user_bias = Embedding(num_users, 1)
        self.movie_embedding = Embedding(num_movies, embedding_size, embeddings_initializer='he_normal')
        self.movie_bias = Embedding(num_movies, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        movie_vector = self.movie_embedding(inputs[:, 1])
        movie_bias = self.movie_bias(inputs[:, 1])

        dot_user_movie = tf.reduce_sum(user_vector * movie_vector, axis=1, keepdims=True)
        x = dot_user_movie + user_bias + movie_bias
        return tf.nn.sigmoid(x)

X = df_ratings[['user', 'movie']].values
y = df_ratings['rating'].values

y = (y - y.min()) / (y.max() - y.min())

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RecommenderNet(num_users, num_movies)
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

history = model.fit(X_train, y_train, epochs=10, verbose=1, validation_data=(X_test, y_test))

df_ratings

def show_simple_recommendations(user_id_target, model, df_ratings, df_movies, user_encoder, movie_encoder, top_n=10):
    encoded_user_id = user_encoder.transform([user_id_target])[0]

    all_movie_encoded_ids = np.arange(len(movie_encoder.classes_))

    user_movie_input = np.array([[encoded_user_id, movie_id] for movie_id in all_movie_encoded_ids])
    predicted_ratings = model.predict(user_movie_input).flatten()

    top_indices = predicted_ratings.argsort()[-top_n:][::-1]
    top_movie_encoded_ids = all_movie_encoded_ids[top_indices]
    top_movie_ids = movie_encoder.inverse_transform(top_movie_encoded_ids)

    recommendations = df_movies[df_movies['id'].isin(top_movie_ids)][['id', 'title', 'overview']].copy()
    recommendations['predicted_rating'] = predicted_ratings[top_indices]

    print(f"Rekomendasi film untuk User ID {user_id_target}:")

    for i, row in recommendations.iterrows():
        print(f"----------------------------")
        print(f"Judul: {row['title']}")
        print(f"ID Film: {row['id']}")
        print(f"Prediksi Rating: {row['predicted_rating']:.2f}")
        print(f"Sinopsis: {row['overview'][:250]}...\n")

    return recommendations.reset_index(drop=True)

rekomendasi = show_simple_recommendations(
    user_id_target=30,
    model=model,
    df_ratings=df_ratings,
    df_movies=df_movies,
    user_encoder=user_encoder,
    movie_encoder=movie_encoder,
    top_n=5
)

"""# **8. Evaluasi**"""

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Mean Squared Error')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['mae'], label='Train MAE', marker='o')
plt.plot(history.history['val_mae'], label='Validation MAE', marker='o')
plt.title('Mean Absolute Error')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()